{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# baseline_100M ---> output 256 * 256 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self, noise_dim):\n",
    "        super().__init__()\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose2d(noise_dim,256*8, kernel_size=8,padding=0,stride=4),\n",
    "            torch.nn.BatchNorm2d(256*8),\n",
    "            torch.nn.LeakyReLU(0.1),\n",
    "            torch.nn.Dropout2d(0.1),\n",
    "            torch.nn.ConvTranspose2d(256*8,256*4,kernel_size=6,padding=1,stride=4),\n",
    "            torch.nn.BatchNorm2d(256*4),\n",
    "            torch.nn.LeakyReLU(0.1),\n",
    "            torch.nn.Dropout2d(0.1),\n",
    "            torch.nn.ConvTranspose2d(256*4,256*2,kernel_size=6,padding=2,stride=2),\n",
    "            torch.nn.BatchNorm2d(256*2),\n",
    "            torch.nn.LeakyReLU(0.1),\n",
    "            torch.nn.Dropout2d(0.1),\n",
    "            torch.nn.ConvTranspose2d(256*2, 256, kernel_size=4, padding=1, stride=2),\n",
    "            torch.nn.BatchNorm2d(256),\n",
    "            torch.nn.LeakyReLU(0.1),\n",
    "            torch.nn.Dropout2d(0.1),\n",
    "            torch.nn.ConvTranspose2d(256,3,kernel_size=2,padding=0,stride=2),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "        self.apply(weights_init)\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deep_200M ---> output 128*128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self, noise_dim):\n",
    "        super().__init__()\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose2d(noise_dim,256*4, kernel_size=10,padding=1),\n",
    "            torch.nn.BatchNorm2d(256*4),\n",
    "            torch.nn.LeakyReLU(0.1),\n",
    "            torch.nn.Dropout2d(0.1),\n",
    "            torch.nn.ConvTranspose2d(256*4,256*4,kernel_size=4,padding=1,stride=2),\n",
    "            torch.nn.BatchNorm2d(256*4),\n",
    "            torch.nn.LeakyReLU(0.1),\n",
    "            torch.nn.Dropout2d(0.1),\n",
    "            torch.nn.ConvTranspose2d(256*4,256*2,kernel_size=4,padding=1,stride=2),\n",
    "            torch.nn.BatchNorm2d(256*2),\n",
    "            torch.nn.LeakyReLU(0.1),\n",
    "            torch.nn.Dropout2d(0.1),\n",
    "            torch.nn.ConvTranspose2d(256*2,256,kernel_size=3,padding=1,stride=1),\n",
    "            torch.nn.BatchNorm2d(256),\n",
    "            torch.nn.LeakyReLU(0.1),\n",
    "            torch.nn.Dropout2d(0.1),\n",
    "            torch.nn.ConvTranspose2d(256,128,kernel_size=4,padding=1,stride=2),\n",
    "            torch.nn.BatchNorm2d(128),\n",
    "            torch.nn.LeakyReLU(0.1),\n",
    "            torch.nn.Dropout2d(0.1),\n",
    "            torch.nn.ConvTranspose2d(128,64,kernel_size=3,padding=1,stride=1),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.LeakyReLU(0.1),\n",
    "            torch.nn.Dropout2d(0.1),\n",
    "            torch.nn.ConvTranspose2d(64,64,kernel_size=3,padding=1,stride=1),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.LeakyReLU(0.1),\n",
    "            torch.nn.Dropout2d(0.1),\n",
    "            torch.nn.ConvTranspose2d(64,32,kernel_size=4,padding=1,stride=2),\n",
    "            torch.nn.BatchNorm2d(32),\n",
    "            torch.nn.LeakyReLU(0.1),\n",
    "            torch.nn.Dropout2d(0.1),\n",
    "            torch.nn.ConvTranspose2d(32, 3, kernel_size=3, padding=1, stride=1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "        self.apply(weights_init)\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3,64,kernel_size=3,stride=2,padding=1),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.LeakyReLU(0.1),\n",
    "            torch.nn.Conv2d(64,128,kernel_size=3,stride=2,padding=1),\n",
    "            torch.nn.BatchNorm2d(128),\n",
    "            torch.nn.LeakyReLU(0.1),\n",
    "            torch.nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            torch.nn.Dropout2d(0.2),\n",
    "            torch.nn.Conv2d(128,256,kernel_size=3,stride=2,padding=1),\n",
    "            torch.nn.BatchNorm2d(256),\n",
    "            torch.nn.LeakyReLU(0.1),\n",
    "            torch.nn.Dropout2d(0.2),\n",
    "            torch.nn.Conv2d(256,512,kernel_size=3,stride=1,padding=1),\n",
    "            torch.nn.BatchNorm2d(512),\n",
    "            torch.nn.LeakyReLU(0.1),\n",
    "            torch.nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            torch.nn.Flatten(start_dim=1),\n",
    "            torch.nn.Linear(8192,512),\n",
    "            torch.nn.LeakyReLU(0.1),\n",
    "            torch.nn.Dropout(0.2),\n",
    "            torch.nn.Linear(512,1)\n",
    "        )\n",
    "        self.apply(weights_init)\n",
    "    def forward(self,x):\n",
    "        return self.model(x)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
